table(unlist(sapply(unb.prof, function(x) (x$producao_bibiografica$TEXTO_EM_JORNAIS$ano))))
# Número de pessoas que realizaram diferentes tipos de orientações
length(unlist(sapply(unb.prof, function(x) names(x$orientacoes_academicas))))
# Número de pessoas por tipo de orientação
table(unlist(sapply(unb.prof, function(x) names(x$orientacoes_academicas))))
#Número de orientações concluidas
sum(sapply(unb.prof, function(x) length(x$orientacoes_academicas$ORIENTACAO_CONCLUIDA_MESTRADO$ano)))
sum(sapply(unb.prof, function(x) length(x$orientacoes_academicas$ORIENTACAO_CONCLUIDA_DOUTORADO$ano)))
sum(sapply(unb.prof, function(x) length(x$orientacoes_academicas$ORIENTACAO_CONCLUIDA_POS_DOUTORADO$ano)))
# Número de pessoas por quantitativo de orientações por pessoa 0 = 1; 1 = 2...
table(unlist(sapply(unb.prof, function(x) length(x$orientacoes_academicas$ORIENTACAO_CONCLUIDA_MESTRADO$ano))))
table(unlist(sapply(unb.prof, function(x) length(x$orientacoes_academicas$ORIENTACAO_CONCLUIDA_DOUTORADO$ano))))
table(unlist(sapply(unb.prof, function(x) length(x$orientacoes_academicas$ORIENTACAO_CONCLUIDA_POS_DOUTORADO$ano))))
# Número de orientações por ano
table(unlist(sapply(unb.prof, function(x) (x$orientacoes_academicas$ORIENTACAO_CONCLUIDA_MESTRADO$ano))))
table(unlist(sapply(unb.prof, function(x) (x$orientacoes_academicas$ORIENTACAO_CONCLUIDA_DOUTORADO$ano))))
table(unlist(sapply(unb.prof, function(x) (x$orientacoes_academicas$ORIENTACAO_CONCLUIDA_POS_DOUTORADO$ano))))
```
###Arquivo Publicação
```{r}
# Visualizar a estrutura do arquivo de Publicacao
#jsonedit(unb.pub)
#Criando um data-frame com todos os anos
unb.pub.df <- data.frame()
for (i in 1:length(unb.pub[[1]]))
unb.pub.df <- rbind(unb.pub.df, unb.pub$PERIODICO[[i]])
glimpse(unb.pub.df)
# Limpando o data-frame de listas
unb.pub.df$autores <- gsub("\",\"|\", \"", "; ", unb.pub.df$autores)
unb.pub.df$autores <- gsub("\"|c\\(|\\)", "", unb.pub.df$autores)
unb.pub.df$`autores-endogeno` <- gsub(",", ";", unb.pub.df$`autores-endogeno`)
unb.pub.df$`autores-endogeno` <- gsub("\"|c\\(|\\)", "", unb.pub.df$`autores-endogeno`)
glimpse(unb.pub.df)
```
###Arquivo Orientação
```{r}
#Orientação
#Visualizar a estrutura do json no painel Viewer
#jsonedit(unb.adv)
#Reunir todos os anos e orientações concluidas em um mesmo data-frame
unb.adv.tipo.df <- data.frame(); unb.adv.df <- data.frame()
for (i in 1:length(unb.adv[[1]]))
unb.adv.tipo.df <- rbind(unb.adv.tipo.df, unb.adv$ORIENTACAO_CONCLUIDA_POS_DOUTORADO[[i]])
unb.adv.df <- rbind(unb.adv.df, unb.adv.tipo.df); unb.adv.tipo.df <- data.frame()
for (i in 1:length(unb.adv[[1]]))
unb.adv.tipo.df <- rbind(unb.adv.tipo.df, unb.adv$ORIENTACAO_CONCLUIDA_DOUTORADO[[i]])
unb.adv.df <- rbind(unb.adv.df, unb.adv.tipo.df); unb.adv.tipo.df <- data.frame()
for (i in 1:length(unb.adv[[1]]))
unb.adv.tipo.df <- rbind(unb.adv.tipo.df, unb.adv$ORIENTACAO_CONCLUIDA_MESTRADO[[i]])
unb.adv.df <- rbind(unb.adv.df, unb.adv.tipo.df)
glimpse(unb.adv.df)
#Transformar as colunas de listas em caracteres eliminando c("")
unb.adv.df$nome_orientadores <- gsub("\"|c\\(|\\)", "", unb.adv.df$nome_orientadores)
unb.adv.df$id_lattes_orientadores <- gsub("\"|c\\(|\\)", "", unb.adv.df$id_lattes_orientadores)
#Separar as colunas com dois orientadores
unb.adv.df <- separate(unb.adv.df, nome_orientadores, into = c("ori1", "ori2"), sep = ",")
unb.adv.df <- separate(unb.adv.df, id_lattes_orientadores, into = c("idLattes1", "idLattes2"), sep = ",")
#Numero de orientacoes por ano
table(unb.adv.df$ano)
#Tabela com nome de professor e numero de orientacoes
head(sort(table(rbind(unb.adv.df$ori1, unb.adv.df$ori2)), decreasing = TRUE), 20)
```
##CRISP-DM Fase.Atividade 2.4 - Verificação da qualidade dos dados.
Como já informado, a verificação da qualidade dos dados envolve responder se os dados disponíveis estão realmente completos.
As informações disponíveis são suficientes para o trabalho proposto?
Neste projeto, a verificação da qualidade dos dados é responsabilidade dos alunos.
#CRISP-DM Fase 3 -  __Preparação dos Dados__
Como já informado, na fase de __Preparação dos Dados__ os _datasets_ que serão utilizados em todo o trabalho são construídos a partir dos dados brutos. Aqui os dados são “filtrados” retirando-se partes que não interessam e selecionando-se os “campos” necessários para o trabalho de mineração.
São 5 as atividades genéricas nesta fase de preparação dos dados, a seguir divididas em subseções
##CRISP-DM Fase.Atividade 3.1 - Seleção dos dados.
Como já informado, a seleção dos dados envolve identificar quais dados, da nossa "montanha de dados", serão realmente utilizados.
Quais variáveis dos dados brutos serão convertidas para o _dataset_?
Não é raro cometer o erro de selecionar dados para um modelo preditivo com base em uma falsa ideia de que aqueles dados contém a resposta para o modelo que se quer construir. Surge o cuidado de se separar o sinal do ruído (Silver, Nate. The Signal and the Noise: Why so many predictions fail — but some don’t. USA: The Penguin Press HC, 2012.).
##CRISP-DM Fase.Atividade 3.2 - Limpeza dos dados
##CRISP-DM Fase.Atividade 3.3 - Construção dos dados
Como já informado, a construção dos dados envolve a criação de novas variáveis a partir de outras presentes nos _datasets_.
```{r}
# Funcoes
# converte as colunas de um dataframe tipo lista em tipo character
cv_tplista2tpchar <- function( df  ) {
for( variavel in names(df)) {
if (class(df[[variavel]]) == "list" ) {
df[[variavel]] <- lapply(df[[variavel]] ,   function(x)   lista2texto( x  ) )
df[[variavel]] <- as.character( df[[variavel]] )
}
}
return(df)
}
###
# converte o conteudo de lista em array de characters
lista2texto <- function( lista  ) {
if(is.null(lista)) {
return ( NULL )
}
saida <- ""
for( j in 1:length(lista)) {
for( i in 1:length(lista[[j]]) ) {
elemento <- lista[[j]][i]
if( !is.null(elemento)) {
if( i == length(lista[[j]]) & j == length(lista)  ) {
# se for o ultimo elemento nao coloque o ponto e virgula no final
saida <- paste0( saida , elemento  )
} else {
# enquanto nao for o ultimo coloque ; separando os elementos concatenados
saida <- paste0( saida , elemento , sep = " ; ")
}
}
}
}
return( saida )
}
# Converte producao elattes separada por anos em um unico dataframe
converte_producao2dataframe<- function( lista_producao ) {
df_saida <- NULL
for( ano in names(lista_producao)) {
df_saida <- rbind(df_saida , lista_producao[[ano]])
}
# converte tipo lista em array de character
df_saida <- cv_tplista2tpchar(df_saida)
return(df_saida)
}
#concatena dois dataframes com  colunas diferentes
concatenadf <- function( df1, df2) {
#cria colunas de df1 que faltam em df2
for( coluna in names(df1 ) ) {
if( !is.element(coluna, names(df2) )) {
df2[coluna] <- NA
}
}
#cria colunas de df2 que faltam em df1
for( coluna in names(df2 ) ) {
if( !is.element(coluna, names(df1) )) {
df1[coluna] <- NA
}
}
#faz o rbind dos dois dataframes
df_final <- rbind(df1 , df2)
return(df_final)
}
# Extracao dos perfis dos professores
extrai_1perfil <- function( professor ) {
idLattes <- names(professor)
nome <- professor[[idLattes]]$nome
resumo_cv <- professor[[idLattes]]$resumo_cv
endereco_profissional <- professor[[idLattes]]$endereco_profissional #list
instituicao <- endereco_profissional$instituicao
orgao <- endereco_profissional$orgao
unidade <- endereco_profissional$unidade
DDD <- endereco_profissional$DDD
telefone <- endereco_profissional$telefone
bairro <- endereco_profissional$bairro
cep <- endereco_profissional$cep
cidade <- endereco_profissional$cidade
senioridade <- professor[[idLattes]]$senioridade
df_1perfil <- data.frame( idLattes , nome, resumo_cv ,instituicao ,
orgao, unidade , DDD, telefone, bairro,cep,cidade , senioridade,
stringsAsFactors = FALSE)
return(df_1perfil)
}
extrai_perfis <- function(jsonProfessores) {
df_saida <- data.frame()
for( i in 1:length(jsonProfessores)) {
jsonProfessor <- jsonProfessores[i]
df_professor <- extrai_1perfil(jsonProfessor)
if( nrow(df_saida) > 0 ) {
df_saida <- rbind(df_saida , df_professor)
} else {
df_saida <- df_professor
}
}
return(df_saida)
}
# Extracao da producao bibliografica dos professores
extrai_1producao <- function(professor) {
idLattes <- names(professor)
df_1producao <<- NULL
producao_bibliografica <- professor[[idLattes]]$producao_bibiografica  #list
for( tipo_producao in names(producao_bibliografica)) {
df_temporario <- cv_tplista2tpchar ( producao_bibliografica[[tipo_producao]])
df_temporario$tipo_producao <-  tipo_producao
df_temporario$idLattes <-  idLattes
df_1producao <- concatenadf( df_1producao , df_temporario  )
}
return(df_1producao)
}
extrai_producoes <- function( jsonProfessores) {
df_saida <- data.frame()
for( i in 1:length(jsonProfessores)) {
jsonProfessor <- jsonProfessores[i]
df_producao <- extrai_1producao(jsonProfessor)
if( nrow(df_saida) > 0 ) {
df_saida <- concatenadf(df_saida , df_producao)
} else {
df_saida <- df_producao
}
}
df_saida <- df_saida %>% filter( !is.na(tipo_producao))
return(df_saida)
}
# Extracao das orientacoes dos professores
extrai_1orientacao <- function(professor) {
idLattes <- names(professor)
df_1orientacao <- NULL
orientacoes_academicas  <- professor[[idLattes]]$orientacoes_academicas  #list
for( orientacao in names(orientacoes_academicas )) {
df_temporario <- cv_tplista2tpchar ( orientacoes_academicas[[orientacao]])
df_temporario$orientacao <-  orientacao
df_temporario$idLattes <-  idLattes
df_1orientacao <- concatenadf( df_1orientacao , df_temporario  )
}
return(df_1orientacao)
}
extrai_orientacoes <- function(jsonProfessores) {
df_saida <- data.frame()
for( i in 1:length(jsonProfessores)) {
jsonProfessor <- jsonProfessores[i]
df_orientacao <- extrai_1orientacao(jsonProfessor)
if( nrow(df_saida) > 0 ) {
df_saida <- concatenadf(df_saida , df_orientacao)
} else {
df_saida <- df_orientacao
}
}
df_saida <- df_saida %>% filter(!is.na(idLattes))
return(df_saida)
}
# Extracao das areas de atuacao dos professores
extrai_1area_de_atuacao <- function(professor){
idLattes <- names(professor)
df_1area <-  professor[[idLattes]]$areas_de_atuacao
df_1area$idLattes <- idLattes
return(df_1area)
}
extrai_areas_atuacao <- function(jsonProfessores){
df_saida <- data.frame()
for( i in 1:length(jsonProfessores)) {
jsonProfessor <- jsonProfessores[i]
df_area_atuacao <- extrai_1area_de_atuacao(jsonProfessor)
if( nrow(df_saida) > 0 ) {
df_saida <- concatenadf(df_saida , df_area_atuacao)
} else {
df_saida <- df_area_atuacao
}
}
df_saida <- df_saida %>% filter( !is.na(idLattes))
return(df_saida)
}
########################### Inicio
# colocar o diretorio onde está o arquivo json de perfis a serem lidos
unb.prof.json <- read_file("ci/ci.profile.json")
unb.prof.df.capes <- read.csv("PesqPosCapes.csv",
sep = ";", header = TRUE, colClasses = "character")
unb.prof <- fromJSON(unb.prof.json)
length(unb.prof)
# extrai perfis dos professores
unb.prof.df.professores <- extrai_perfis(unb.prof)
# extrai producao bibliografica de todos os professores
unb.prof.df.publicacoes <- extrai_producoes(unb.prof)
#extrai orientacoes
unb.prof.df.orientacoes <- extrai_orientacoes(unb.prof)
#extrai areas de atuacao
unb.prof.df.areas.de.atuacao <- extrai_areas_atuacao(unb.prof)
#salva os daframes
save(unb.prof.df.professores, unb.prof.df.publicacoes,
unb.prof.df.orientacoes, unb.prof.df.areas.de.atuacao, file = "dataframes.Rda")
#cria arquivo para análise
unb.prof.df <- data.frame()
unb.prof.df <- unb.prof.df.professores %>%
select(idLattes, nome, resumo_cv, senioridade) %>%
left_join(
unb.prof.df.orientacoes %>%
select(orientacao, idLattes) %>%
filter(!grepl("EM_ANDAMENTO", orientacao)) %>%
group_by(idLattes) %>%
count(orientacao) %>%
spread(key = orientacao, value = n),
by = "idLattes") %>%
left_join(
unb.prof.df.publicacoes %>%
select(tipo_producao, idLattes) %>%
filter(!grepl("ARTIGO_ACEITO", tipo_producao)) %>%
group_by(idLattes) %>%
count(tipo_producao) %>%
spread(key = tipo_producao, value = n),
by = "idLattes") %>%
left_join(
unb.prof.df.areas.de.atuacao %>%
select(area, idLattes) %>%
group_by(idLattes) %>%
summarise(n_distinct(area)),
by = "idLattes") %>%
left_join(
unb.prof.df.capes %>%
select(AreaPos, idLattes) %>%
group_by(idLattes) %>%
summarise(n_distinct(AreaPos)),
by = "idLattes")
glimpse(unb.prof.df)
```
##CRISP-DM Fase.Atividade 3.4 - Integração dos dados
Como já informado, a integração dos dados envolve a união (merge) de diferentes tabelas para criar um único _dataset_ para ser utilizado no R, por exemplo.
##CRISP-DM Fase.Atividade 3.5 -  Formatação dos dados
Como já informado, a formatação de dados envolve a realização de pequenas alterações na estrutura dos dados, como a ordem das variáveis, para permitir a execução de determinado método de data mining.
#CRISP-DM Fase 4 - __Modelagem__
Como já informado, na fase de __Modelagem__ no CRISP-DM ocorre a construção e avaliação de modelos estatísticos ou computacionais, podendo ser realizada em quatro atividades genéricas, a seguir organizadas na forma de seções
##CRISP-DM Fase.Atividade 4.1 - Seleção das técnicas de modelagem
##CRISP-DM Fase.Atividade 4.2 -  Realização de testes de modelagem
Como já informado, na realização de testes de modelagem diferentes modelos estatísticos ou computacionais são previamente testados e avaliados. Pode-se dividir o _dataset_ criado na etapa anterior para se ter uma base de treino na construção de modelos, e outra pequena parte para validar  e avaliar a eficiência de cada modelo criado até se chegar ao mais “eficiente”.
##CRISP-DM Fase.Atividade 4.3 -  Construção do modelo definitivo
Como já informado, a construçao do modelo definitivo é realizada com base na melhor experiência do passo anterior.
##CRISP-DM Fase.Atividade 4.4 - Avaliação do modelo
#CRISP-DM Fase 5 - __Avaliação__
Como já informado, na fase de __Avaliação__ do CRISP-DM os resultados não são apenas avaliados, mas se verifica se existem questões relacionadas à organização que não foram suficientemente abordadas. Deve-se refletir se o uso arepetido do modelo criado pode trazer algum “efeito colateral” para a organização.
Como já informado, nesta fase, pode-se trabalhar com 3 atividades genéricas, a seguir distribuídas em seções.
##CRISP-DM Fase.Atividade 5.1 - Avaliação dos resultados
##CRISP-DM Fase.Atividade 5.2 - Revisão do processo
Como já informado, durante a revisão do processo verifica-se se o modelo foi construído adequadamente. As variáveis (passadas) para construir o modelo estarão disponíveis no futuro?
##CRISP-DM Fase.Atividade 5.3 -  Determinação dos etapas seguintes
Como já informado, pode ser necessário decidir-se por finalizar o projeto, passar à etapa de desenvolvimento, ou rever algumas fases anteriores para a melhoria do projeto.
#CRISP-DM Fase 6 - __Implantação__ (_deployment_)
Como já informado, na fase de __Implantação__ (_deployment_) se realiza o planejamento de implantação dos produtos desenvolvidos (scripts, no caso do executado nesta disciplina) para o ambiente operacional, para seu uso repetitivo, envolvendo atividades de monitoramento e manutenção do sistema (script) desenvolvido. A fase de implantação concluir com a produção e apresentação do relatório final com os resultados do projeto.
Como já informado, são seis as atividades genéricas na fase de __implantação__, a seguir apresentadas na forma de seções.
##CRISP-DM Fase.Atividade 6.1 -  Planejamento da transição
De que forma os produtos desenvolvidos pelo grupo poderiam ser colocados em uso prático regular, na organização cliente?
##CRISP-DM Fase.Atividade 6.2 -  Planejamento do monitoramento dos produtos
De que forma seria possível realizar o monitoramento do funcionamento dos produtos em utilização no ambiente operacional?
##CRISP-DM Fase.Atividade 6.3 -  Planejamento de manuteção
que manutenções, ajustes, mudanças, poderia ter que ser eventualmente realizadas no produto (scripts), quando em uso no ambiente operacional do cliente?
##CRISP-DM Fase.Atividade 6.4 -  Produção do relatório final
A entrega do relatório do grupo, tomando como base este aqui, reflete  a execução desta etapa.
##CRISP-DM Fase.Atividade 6.5 -  Apresentação do relatório final
Como já informado, não será feita apresentação do relatório, mas esperamos que publicações científicas possam ser geradas com pelo seu grupo, com o apoio dos professores da disciplina.
##CRISP-DM Fase.Atividade 6.6 -  Revisão sobre a execução do projeto
Deve-se fazer aqui o registro de lições aprendidas, bem como traçadas perspectivas futuras de aprimoramento deste trabalho, da disciplina de Ciência de Dados para Todos etc.
# Referências
* Azevedo, Mário Luiz Neves de, João Ferreira de Oliveira, e Afrânio Mendes Catani. “O Sistema Nacional de Pós-Graduação (SNPG) e o Plano Nacional de Educação (PNE 2014-2024): regulação, avaliação e financiamento”. Revista Brasileira de Política e Administração da Educação 32, nº 3 (2016). http://dx.doi.org/10.21573/vol32n32016.68576.
* Can, Fazli, Tansel Özyer, e Faruk Polat, orgs. State of the Art Applications of Social Network Analysis. Lecture Notes in Social Networks. Switzerland: Springer International Publishing, 2014.
* CAPES. “Documentos de Área”. CAPES.gov.br. Acessado 12 de junho de 2018. http://avaliacaoquadrienal.capes.gov.br/documentos-de-area.
* ———. “Plano Nacional de Pós-Graduação - PNPG 2011/2020 Vol. 1”. Brasília - DF, dezembro de 2010. http://www.capes.gov.br/images/stories/download/Livros-PNPG-Volume-I-Mont.pdf.
* ———. “Plano Nacional de Pós-Graduação - PNPG 2011/2020 Vol. 2”. Brasília - DF, dezembro de 2010. http://www.capes.gov.br/images/stories/download/PNPG_Miolo_V2.pdf.
* ———. “Sucupira: coleta de dados, docentes de pós-graduação stricto sensu no Brasil 2015”. CAPES - Banco de Metadados, 16 de março de 2016. http://metadados.capes.gov.br/index.php/catalog/63.
* Chapman, Pete, Julian Clinton, Randy Kerber, Thomas Khabaza, Thomas Reinartz, Colin Shearer, e Rüdiger Wirth. “CRISP-DM 1.0: Step-by-Step Data Mining Guide”. USA: CRISP-DM Consortium, 2000. https://www.the-modeling-agency.com/crisp-dm.pdf.
* Datacamp. “Machine Learning with R (Skill Track)”. Datacamp, 2018. https://www.datacamp.com/tracks/machine-learning.
* Fernandes, Jorge H C, e Ricardo Barros Sampaio. “DataScienceForAll”. Zotero, 13 de junho de 2018. https://www.zotero.org/groups/2197167/datascienceforall.
* ———. “Especificação do Trabalho Final da Disciplina de Ciência de Dados para Todos 2017.2: Estudo sobre a visibilidade internacional da produção científica das pós-graduações vinculadas às áreas de conhecimento da CAPES, na Universidade de Brasília (Comunicação Interna)”. Disciplina 116297 - Tópicos Avançados em Computadores, turma D, do semestre 2017.2, do Departamento de Ciência da Computação do Instituto de Ciências Exatas da Universidade de Brasília, 28 de novembro de 2017. https://aprender.ead.unb.br/pluginfile.php/474549/mod_resource/content/1/Estudo%20da%20Cie%CC%82ncia.pdf.
* Fernandes, Jorge H C, Ricardo Barros Sampaio, e João Ribas de Moura. “Ciência de Dados para Todos (Data Science   For All) - 2018.1 - Análise da Produção Científica e Acadêmica da Universidade de Brasília - Modelo de Relatório Final da Disciplina - Departamento de Ciência da Computação da UnB”. Disciplina 116297 - Tópicos Avançados em Computadores, turma D, do semestre 2018.1, do Departamento de Ciência da Computação do Instituto de Ciências Exatas da Universidade de Brasília, 13 de junho de 2018.
* Frickel, Scott, e Kelly Moore. The New Political Sociology of Science: Institutions, Networks, and Power. Science and technology in society. USA: The University of Wisconsin Press, 2006.
* Graduate Prospects Ltd. “Job profile: Higher education lecturer”, 2018. https://www.prospects.ac.uk/job-profiles/higher-education-lecturer.
* Kalpazidou Schmidt, Evanthia, e Ebbe Krogh Graversen. “Persistent factors facilitating excellence in research environments”. Higher Education 75, nº 2 (1º de fevereiro de 2018): 341–63. https://doi.org/10.1007/s10734-017-0142-0.
* Kilduff, Martin, e Wenpin Tsai. Social Networks and Organizations. UK: Sage Publications, 2003.
* Kolaczyk, Eric D., e Gábor Csárdi. Statistical Analysis of Network Data with R. USA: Springer, 2014.
* Kuhn, Max, Jed Wing, Steve Weston, Andre Williams, Chris Keefer, Allan Engelhardt, Tony Cooper, et al. “Package ‘Caret’ - Classification and Regression Training”, 27 de maio de 2018. https://cran.r-project.org/web/packages/caret/caret.pdf.
* Leite, Fernando César Lima. “Considerações básicas sobre  a Avaliação do Sistema  Nacional de Pós-Graduação”. Comunicação Pessoal (slides). Universidade de Brasília, abril de 2018. https://aprender.ead.unb.br/pluginfile.php/502250/mod_resource/content/1/Considera%C3%A7%C3%B5es%20b%C3%A1sicas%20sobre%20a%20Avalia%C3%A7%C3%A3o%20do%20Sistema%20Nacional.pdf.
* Lusher, Dean, Johan Koskinen, e Garry Robins, orgs. Exponential Random Graph Models for Social Networks: Theory, methods, and applications. Structural Analysis in the Social Sciences. USA: Cambridge University Press, 2013.
* Mariscal, Gonzalo, Óscar Marbán, e Covadonga Fernández. “A survey of data mining and knowledge discovery process models and methodologies”. The Knowledge Engineering Review 25, nº 2 (2010): 137–66. https://doi.org/10.1017/S0269888910000032.
* Nery, Guilherme, Ana Paula Bragaglia, Flávia Clemente, e Suzana Barbosa. “Nem tudo parece o que é: Entenda o que é plágio”. Instituto de Arte e Comunicação Social da UFF, 2009. http://www.noticias.uff.br/arquivos/cartilha-sobre-plagio-academico.pdf.
* Nooy, Wouter de, Andrej Mrvar, e Vladimir Batagelj. Exploratory Social Network Analysis with Pajek. Structural Analysis in the Social Sciences. USA: Routldge, 2005.
* Pátaro, Cristina Saitê de Oliveira, e Frank Antonio Mezzomo. “Sistema Nacional de Pós-Graduação no Brasil: estrutura, resultados e desafios para política de Estado - Lívio Amaral”. Revista Educação e Linguagens 2, nº 3 (julho de 2013): 11–17.
* Schwartzman, Simon. “A Ciência da Ciência”. Ciência Hoje 2, nº 11 (março de 1984): 54–59.
* Silver, Nate. The Signal and the Noise: Why so many predictions fail — but some don’t. USA: The Penguin Press HC, 2012.
* Vicari, Donatella, Akinori Okada, Giancarlo Ragozini, e Claus Wiehs. Analysis and Modeling of Complex Data in Behavioral and Social Sciences. Studies in Classifi cation, Data Analysis, and Knowledge Organization. Switzerland: Springer, 2014.
* Wickham, Hadley, e Garrett Grolemund. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. USA: O’Reilly, 2016.
ci.perfil$`1923828283438124`$areas_de_atuacao
ci.perfil$`5121339738881627`$areas_de_atuacao
ci.perfil$`5121339738881627`$nome
ci.perfil$`5121339738881627`$resumo_cv
ci.perfil$`5121339738881627`$orientacoes_academicas
#Análise inicial dos arquivos geraos pelo e-Lattes
#Pacotes para serem ativados
library(tidyverse)
library(jsonlite); library(listviewer)
library(igraph)
#Pasta com códigos e arquivos
setwd("~/Projects/DS4ALL/Relatorio") #Pasta contendo os arquivos
#upload de arquivo com funções para transformar listas em Data Frames e objeto igraph
source("elattes.ls2df.R")
#Definição da pasta e leitura de arquivos
perfil <- fromJSON("./unbpos/unbpos.profile.json")
public <- fromJSON("./unbpos/unbpos.publication.json")
orient <- fromJSON("./unbpos/unbpos.advise.json")
graphl <- fromJSON("./unbpos/unbpos.graph.json")
res.area <- fromJSON("./unbpos/unbpos.researchers_by_area.json")
df.prog <- read.table("./unbpos/PesqPosCapes.csv", sep = ",",
colClasses = "character", encoding = "UTF-8", header = TRUE)
length(perfil)
sum(sapply(perfil, function(x) length(x$producao_bibiografica$ARTIGO_ACEITO$ano)))
sum(sapply(perfil, function(x) length(x$producao_bibiografica$CAPITULO_DE_LIVRO$ano)))
sum(sapply(perfil, function(x) length(x$producao_bibiografica$LIVRO$ano)))
sum(sapply(perfil, function(x) length(x$producao_bibiografica$PERIODICO$ano)))
sum(sapply(perfil, function(x) length(x$producao_bibiografica$TEXTO_EM_JORNAIS$ano)))
# Número de pessoas por grande area
table(unlist(sapply(perfil, function(x) (x$areas_de_atuacao$grande_area))))
table(unlist(sapply(perfil, function(x) names(x$producao_bibiografica))))
# Número de publicações por tipo
perfil$`0011938955607677`$areas_de_atuacao$area
#ciencia da informacao
ci.perfil <- fromJSON("./ciencia_informacao/ci.profile.json")
ci.public <- fromJSON("./ciencia_informacao/ci.publication.json")
ci.orient <- fromJSON("./ciencia_informacao/ci.advise.json")
ci.graphl <- fromJSON("./ciencia_informacao/ci.graph.json")
sum(sapply(ci.perfil, function(x) nrow(x$areas_de_atuacao)))
table(unlist(sapply(ci.perfil, function(x) (x$areas_de_atuacao$grande_area))))
ci.perfil$`1923828283438124`$areas_de_atuacao$area
table(unlist(sapply(perfil, function(x) (x$areas_de_atuacao$area))))
table(unlist(sapply(ci.perfil, function(x) (x$areas_de_atuacao$area))))
table(unlist(sapply(ci.perfil, function(x) (x$areas_de_atuacao$sub_area))))
ci.perfil$`1923828283438124`$areas_de_atuacao$especialidade
table(unlist(sapply(ci.perfil, function(x) (x$areas_de_atuacao$especialidade))))
ci.graphl <- fromJSON("./ciencia_informacao/ci.graph.json")
#comunicacao
co.perfil <- fromJSON("./comunicacao/co.profile.json")
co.perfil$`0796700383761856`$areas_de_atuacao
co.perfil$`2990716660409944`$areas_de_atuacao
co.perfil$`9494858512482573`$areas_de_atuacao
sum(sapply(perfil, function(x) nrow(x$areas_de_atuacao)))
table(unlist(sapply(perfil, function(x) names(x$producao_bibiografica))))
length(unlist(sapply(perfil, function(x) names(x$orientacoes_academicas))))
sum(sapply(orient$ORIENTACAO_CONCLUIDA_DOUTORADO, function(x) length(x$natureza))) +
sum(sapply(orient$ORIENTACAO_CONCLUIDA_MESTRADO, function(x) length(x$natureza)))
##Análise dos dados no formato DF
orient.posdoutorado.df <- ori.ls2df(orient, 6) #pos-Doutorado concluído
orient.doutorado.df <- ori.ls2df(orient, 7) #Doutorado concluído
orient.posdoutorado.df$nome_aluno
orient.doutorado.df$nome_aluno
count(orient.posdoutorado.df)
count(orient.doutorado.df)
orient.mestrado.df <- ori.ls2df(orient, 8) #Mestrado concluído
count(orient.doutorado.df + orient.mestrado.df + orient.posdoutorado.df)
count(orient.doutorado.df) + count(orient.mestrado.df) + count(orient.posdoutorado.df)
orient.posdoutorado.df <- ori.ls2df(orient, 6) #pos-Doutorado concluído
orient.doutorado.df <- ori.ls2df(orient, 7) #Doutorado concluído
orient.mestrado.df <- ori.ls2df(orient, 8) #Mestrado concluído
orient.df <- rbind(rbind(orient.posdoutorado.df, orient.doutorado.df), orient.mestrado.df)
ggplot(orient.df,aes(ano,fill=natureza)) +
geom_bar(stat = "count", position="dodge") +
ggtitle("Natureza das Orientações Completas Por Ano") +
theme(legend.position="right",legend.text=element_text(size=7)) +
guides(fill=guide_legend(nrow=5, byrow=TRUE, title.position = "top")) +
labs(x="Ano",y="Quantidade")
count(ci.perfil)
nrows(ci.perfil)
nrow(ci.perfil)
summarize(ci.perfil)
summarise(ci.perfil)
ci.perfil
length(ci.perfil)
ci.perfil$`8046282601245273`
# Número de publicações por tipo
sum(sapply(ci.perfil, function(x) length(x$producao_bibiografica$ARTIGO_ACEITO$ano)))
sum(sapply(ci.perfil, function(x) length(x$producao_bibiografica$CAPITULO_DE_LIVRO$ano)))
sum(sapply(ci.perfil, function(x) length(x$producao_bibiografica$LIVRO$ano)))
sum(sapply(ci.perfil, function(x) length(x$producao_bibiografica$PERIODICO$ano)))
sum(sapply(ci.perfil, function(x) length(x$producao_bibiografica$TEXTO_EM_JORNAIS$ano)))
####
###Publicação
##Análise dos dados no formato lista
#Número de Publicações em periódicos
sum(sapply(public$PERIODICO, function(x) length(x$natureza)))
#anos analisados
names(public$PERIODICO)
#20 revistas mais publicadas
#Mesma visão que anterior mas agora trabalhando no DataFrame
head(sort(table(public.periodico.df$periodico), decreasing = TRUE), 20)
##Análise dos dados no formato DF
public.periodico.df <- pub.ls2df(public, 1) #artigos
#20 revistas mais publicadas
#Mesma visão que anterior mas agora trabalhando no DataFrame
head(sort(table(public.periodico.df$periodico), decreasing = TRUE), 20)
#20 revistas mais publicadas
#Mesma visão que anterior mas agora trabalhando no DataFrame
head(sort(table(public.periodico.df$periodico), decreasing = TRUE), 20)
#Visualização
# Gráfico de barras
public.periodico.df %>%
group_by(ano) %>%
summarise(Quantidade = n()) %>%
ggplot(aes(x = ano, y = Quantidade)) +
geom_bar(position = "stack",stat = "identity", fill = "darkcyan")+
geom_text(aes(label=Quantidade), vjust=-0.3, size=2.5)+
theme_minimal()
##Análise dos dados no formato DF
public.periodico.df <- pub.ls2df(ci.public, 1) #artigos
#20 revistas mais publicadas
#Mesma visão que anterior mas agora trabalhando no DataFrame
head(sort(table(public.periodico.df$periodico), decreasing = TRUE), 20)
#Visualização
# Gráfico de barras
public.periodico.df %>%
group_by(ano) %>%
summarise(Quantidade = n()) %>%
ggplot(aes(x = ano, y = Quantidade)) +
geom_bar(position = "stack",stat = "identity", fill = "darkcyan")+
geom_text(aes(label=Quantidade), vjust=-0.3, size=2.5)+
theme_minimal()
public.periodico.df
public.periodico.df$ano
p <- public.periodico.df$ano = 2017
p <- public.periodico.df$ano = "2017"
public.periodico.df %>% select(titulo)
public.periodico.df %>% filter(ano == 2017) %>% select(titulo)
public.periodico.df %>% filter(ano == 2017)
public.periodico.df %>% filter(ano == 2017) %>% count()
public.periodico.df %>% count()
###Análise dos dados em formato Data Frame
#Arquivo Profile por Currículo
# extrai perfis dos professores
perfil.df.professores <- extrai.perfis(co.perfil)
perfil.df.professores$nome
perfil.df.professores$resumo_cv
length(perfil)
length(co.perfil)
length(ci.perfil)
